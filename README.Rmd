---
output: github_document
bibliography: inst/ref.bib
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  message =  FALSE,
  warning = FALSE
)
```


# glaxo


<!-- badges: start -->
<img src='inst/glaxo-logo.png' align="center" height="240" />

[![CircleCI build status](https://circleci.com/gh/josue-rodriguez/glaxo.svg?style=shield)](https://circleci.com/gh/josue-rodriguez/glaxo)
<!-- badges: end -->

The glaxo package provides an implementation of the relaxed lasso for Gaussian graphical models based on the simple algorithm described in section 2.2 of @meinshausen2007relaxed. Because the classical lasso introduces bias into the parameters, the motivation behind the relaxed lasso is to *debias* the estimates.


## Installation

You can install the released version of glaxo from [CRAN](https://CRAN.R-project.org) with:

``` r
install.packages("glaxo")
```

And the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("josue-rodriguez/glaxo")
```
## Example

The main function in this package is called `glaxo` (relaxed + glasso). In it's most basic form, it takes a `data.frame` or `matrix` and estimates the relaxed lasso solution for the graphical model

```{r example, dpi=320, message=FALSE, warning=FALSE}
library(glaxo)

Y <- psych::bfi[, 1:10]
Y <- na.omit(Y)

relaxed_glasso <- glaxo(Y, progress = FALSE)
```


```{r}
relaxed_glasso
```

The resulting object can also be plotted using standard `ggplot2` syntax

```{r plot, dpi=320}
library(ggnetwork)

plot_edges(relaxed_glasso, layout = "circle") +
  scale_size(range = c(0,2)) +
  guides(size = FALSE) +
  scale_color_manual(values = c("#FAA43A", "#5DA5DA"),
                     name = "",
                     labels = c("Negative", "Positive")) +
  theme_facet() +
  theme(legend.position = "top")
```

Predictions can be made on new data using the relationship between Gaussian graphical models and linear regression [e.g., @stevens1998inverse]

```{r}
preds <- predict(relaxed_glasso, newdata = Y[1001:2000, ])
str(preds)
round(head(preds$predictions), 3)
round(preds$beta_matrix, 3)
```


# Relaxed lasso vs regular lasso

By debiasing the estimates, the relaxed lasso can outperform the traditional lasso solution

```{r}
library(GGMncv)
library(GGMnonreg)


main <- gen_net()
n <- 5000
Y <- MASS::mvrnorm(n, mu = rep(0, 20), main$cors)

regular_glasso <- GGMncv::ggmncv(cor(Y), n = nrow(Y), 
                                 penalty = "lasso", 
                                 ic = "bic",
                                 progress = FALSE)

relaxed_glasso <- glaxo(Y, progress = FALSE, ic = "bic")


glaxo:::compare(Estimate = regular_glasso$adj, True = main$adj)
glaxo:::compare(Estimate = relaxed_glasso$adj, True = main$adj)
```

# References
